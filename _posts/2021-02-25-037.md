---
title: 23일차 - 군집 탐색과 추천 시스템
tags: [boostcamp]
published: true
use_math: true
comments: true
---
    
# 군집 탐색

# 군집 구조와 군집 탐색 문제

- 군집(Communitiy)는 자음 조건들을 만족하는 정점들의 집합이다.
    1. 집합에 속하는 정점 사이에는 많은 간선이 존재한다.
    2. 집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재한다.
- '많은' 혹은 '적은' 이란 애매한 표현이 사용되므로 수학적으로 엄밀한 정의는 아니다.

## 실제 그래프에서의 군집들

- 온라인 소셜 네트워크의 군집들은 사회적 무리를 의미하는 경우가 많다.
    - 온라인 소셜 네트워크의 군집들이 부정 행위와 연관된 경우도 있다.
        - ex) 팔로우 수를 늘려주는 등의 부정 행위
    - 조직 내 분란이 소셜 네트워크 상의 군집으로 표현된 경우도 있다.
    - 키워드 - 광고주 그래프에서는 동일한 주제의 키워드들이 군집을 형성한다.

![Untitled.png](/images/2021-02-25/037/Untitled.png)
- 뉴런간 연결 그래프에서는 군집들이 뇌의 기능적 구성 단위를 의미한다.

## 군집 탐색 문제

- 그래프를 여러 군집으로 '잘' 나누는 문제를 군집 탐색(Community Detection) 문제라고 한다.
- 보통은 각 정점이 한 개의 군집에 속하도록 군집을 나눈다. 비지도 기계학습 문제인 클러스터링(Clusterting)와 상당히 유사하다.
- 이를 잘 풀기 위해선 먼저 **성공적인 군집 탐색**이 무엇인지를 정의할 필요가 있다.

# 군집 구조의 통계적 유의성과 군집성

## 배치 모형(Configuration Model)

![Untitled%201.png](/images/2021-02-25/037/Untitled%201.png)
- 배치 모형에서 임의의 두 정점 $i$와 $j$ 사이에 간선이 존재할 확률은 두 정점의 연결성에 비례한다.

## 군집성(Modularity)

![Untitled%202.png](/images/2021-02-25/037/Untitled%202.png)
- 이 때 배치모형은 기댓값을 사용하는 이유는 배치 모형이 무작위성을 가지기 때문이다.
- 즉 배치 모형과 비교했을 때, 그래프에서 군집 내부 간선의 수가 월등히 많을수록 성공한 군집 탐색이다.
- 군집성은 항상 -1과 +1 사이의 값을 갖는다. 일반적으로 0.3 ~ 0.7 정도의 군집성을 가지면 통계적으로 유의미한 군집들을 찾아냈다고 할 수 있다.

# 군집 탐색 알고리즘

## Girvan-Newman 알고리즘

- 대표적인 Top-Down 방식의 알고리즘이다.
- 전체 그래프에서 탐색을 시작하여 군집들이 서로 분리되도록, 간선을 순차적으로 제거한다.
- 이 때 서로 다른 군집을 연결하는 다리 역할의 간선을 제거한다.

![Untitled%203.png](/images/2021-02-25/037/Untitled%203.png)
- 다리 역할의 간선을 찾아내는 것은 **매개 중심성(Betweeness Centrality)**을 사용한다. 이는 해당 간선이 **정점 간의 최단 경로에 놓이는 횟수**를 의미한다.

![Untitled%204.png](/images/2021-02-25/037/Untitled%204.png)
- 매개 중심성이 높은 간선들이 다른 군집을 연결하는 다리 역할을 하는 것을 알 수 있다.
- Girvan-Newman 알고리즘은 매개 중심성이 높은 간선을 순차적으로 제거한다. 그리고 간선이 제거될 때마다, 매개 중심성을 다시 계산하여 갱신한다. 그리고 이를 간선이 모두 제거될 때까지 반복한다.

![unt.png](/images/2021-02-25/037/unt.png)
- 간선의 제거 정도에 따라서 다른 입도(Granularity)의 군집 구도가 나타난다.

![Untitled%205.png](/images/2021-02-25/037/Untitled%205.png)
- 이 때 간선을 얼마나 제거할 것인가는 군집성을 기준으로 삼는다. 즉 군집성이 최대가 되는 지점까지 간선을 제거한다.
- 단 현재의 연결 요소들을 군집으로 가정하되, 최초의 입력 그래프에서 군집성을 계산한다.
- 정리하면 Givan-Newman 알고리즘은 다음과 같다.
    1. 전체 그래프에서 시작한다.
    2. 매개 중심성이 높은 순서로 간선을 제거하면서, 군집성을 기록한다.
    3. 군집성이 가장 커지는 상황을 복원한다.
    4. 이 때 서로 연결된 정점들, 즉 연결 요소를 하나의 군집으로 간주한다.

## Louvain 알고리즘

- Bottom-Up 방식의 알고리즘이다.

![Untitled%206.png](/images/2021-02-25/037/Untitled%206.png)
- 이 때에도 군집성이 기준으로 군집을 합친다.
- 구체적인 알고리즘의 동작 과정은 다음과 같다.
    1. 개별 정점으로 구성된 크기 1의 군집들로부터 시작한다.
    2. 각 정점 u를 기존 혹은 새로운 군집으로 이동한다. 이 때 군집성이 최대화되도록 군집을 결정한다.
    3. 더 이상 군집성이 증가하지 않을 때까지 2)과정을 반복한다.

![Untitled%207.png](/images/2021-02-25/037/Untitled%207.png)
    4. 각 군집을 하나의 정점으로 하는 군집 레벨의 그래프를 얻은 뒤 다시 3)과정을 수행한다.

![Untitled%208.png](/images/2021-02-25/037/Untitled%208.png)
    5. 위의 과정을 반복하다가 군집성이 증가하지 않으면 알고리즘을 종료한다.

![Untitled%209.png](/images/2021-02-25/037/Untitled%209.png)
# 중첩이 있는 군집 탐색

- 앞서 배운 Girvan-Newman 알고리즘, Louvain 알고리즘은 군집 간의 중첩이 없다고 가정한다.
- 하지만 실제 그래프의 군집들은 중첩되어 있는 경우가 많다.

![Untitled%2010.png](/images/2021-02-25/037/Untitled%2010.png)
- 중첩이 있는 군집을 구하기 위해 아래와 같은 중첩 군집 모형을 가정한다.
    1. 각 정점은 여러 개의 군집에 속할 수 있다.
    2. 각 군집 A에 대해, 같은 군집에 속하는 두 정점은 $P_A$확률로 간선으로 직접 연결된다.
    3. 두 정점이 여러 군집에동시에 속할 경우 간선 연결 확률은 독립적이다. 예를 들어 두 정점이 군집 A와 B에 동시에 속할 경우, 두 정점이 간선으로 직접 연결될 확률은 $1 - (1 - P_A)(1 - P_B)$이다.
    4. 어느 군집에도 함께 속하지 않는 두 정점은 낮은 확률 $\epsilon$으로 직접 연결된다.
- 중첩 군집 모형이 주어지면, 주어진 그래프의 확률을 계산할 수 있다.

![Untitled%2011.png](/images/2021-02-25/037/Untitled%2011.png)
- 중첩 군집 탐색은 주어진 그래프의 확률을 최대화하는 중첩 군집 모형을 찾는 과정이다. 통계 용어를 빌리면, 최우도 추정치(Maximum Likelihood Estimate)를 찾는 과정이다.

![Untitled%2012.png](/images/2021-02-25/037/Untitled%2012.png)
- 중첩 군집 탐색을 용이하게 하기 위하여 **완화된 중첩 군집 모형**을 사용한다. 완화된 중첩 군집 모형에는 각 정점이 각 군집에 속해 있는 정도를 실숫값으로 표현한다.
- 최적화 관점에서는 모형의 매개변수들이 실수 값을 가지기 때문에 익숙한 최적화 도구 (경사하강법 등)을 사용하여 모형을 탐색할 수 있다는 장점이 있다.

![Untitled%2013.png](/images/2021-02-25/037/Untitled%2013.png)
# 추천 시스템

- 추천 시스템은 사용자 각각이 구매할 만한 선호할 만한 상품/영화/영상을 추천한다.
- 추천 시스템의 핵심은 사용자별 구매를 예측하거나 선호를 추정하는 것이다.
- 그래프 관점에서 추천 시스템은 **미래의 간선을 예측하는 문제** 혹은 **누락된 간선의 가중치를 추정하는 문제**로 해석할 수 있다.

![Untitled%2014.png](/images/2021-02-25/037/Untitled%2014.png)
## 내용 기반(Content-based) 추천시스템

- 내용 기반(Content-based)추천은 **각 사용자가 구매/만족했던 상품과 유사한 것**을 추천하는 방법이다.
- 예시로는 동일한 장르의 영화를 추천, 동일한 감독 혹은 배우가 출현한 영화를 추천, 동일한 카테고리의 상품을 추천 등이 있다.
- 네용 기반 추천은 다음 네 가지 단계로 이루어진다.

![Untitled%2015.png](/images/2021-02-25/037/Untitled%2015.png)
1. 첫 단계는 선호했던 상품들의 상품 프로필(Item Profile)을 수집하는 단계이다.
    - 어떤 상품의 상품 프로필이란 해당 상품의 특성을 나열한 벡터이다.

![Untitled%2016.png](/images/2021-02-25/037/Untitled%2016.png)
2. 다음은 사용자 프로필(User Profile)을 구성하는 단계이다.
    - 사용자 프로필은 선호한 상품의 상품 프로필을 선호도를 사용하여 가중 평균하여 계산한다. 즉 사용자 프로필 역시 벡터이다.
    - 앞선 영화 프로필 예시에서는 다음과 같은 형태의 사용자 프로필을 얻을 수 있다.

![Untitled%2017.png](/images/2021-02-25/037/Untitled%2017.png)
3. 다음 단계는 사용자 프로필과 다른 상품들의 상품 프로필을 매칭하는 단계이다. 
    - 사용자 프로필 벡터 $\vec{u}$ 와 상품 프로필 벡터 $\vec v$의 코사인 유사도 $\dfrac {\vec u \cdot \vec v}{\|\vec u\| \|\vec v\|}$를 계산한다. 즉 두 벡터의 사이각의 코사인 값을 계산한다.
    - 코사인 유사도가 높을 수록 해당 사용자가 과거 선호했던 상품들과 해당 상품이 유사함을 의미한다.
4. 마지막 단계는 사용자에게 상품을 추천하는 단계이다. 계산한 코사인 유사도가 높은 상품들을 추천한다.

### 장단점

- 장점
    1. 다른 사용자의 구매 기록이 필요하지 않다.
    2. 독특한 취향의 사용자에게도 추천 가능
    3. 새 상품에 대해서도 추천 가능
    4. 추천의 이유를 제공할 수 있다. 
- 단점
    1. 상품에 대한 부가 정보가 없는 경우에는 사용할 수 없다.
    2. 구매 기록이 없는 사용자에게는 사용할 수 없다.
    3. Overfitting으로 지나치게 협소한 추천을 할 위험이 있다.

## 협업 필터링 추천시스템

- 사용자 - 사용자 협업 필터링은 다음 세 단계로 이루어진다.
    1. 추천의 대상 사용자를 x라고 하자. 우선 x와 **유사한 취향의 사용자**들을 찾는다.
    2. 다음 단계로 유사한 취향의 사용자들이 **선호한 상품**을 찾는다.
    3. 마지막으로 이 상품들을 x에게 추천한다.

![Untitled%2018.png](/images/2021-02-25/037/Untitled%2018.png)
- 사용자 - 사용자 협업 필터링의 핵심은 유사한 취향의 사용자를 찾는 것이다.
- 이 때 취향의 유사도를 계산해야 하는데 이는 **상관 계수(Correlation Coefficient)**를 통해 측정합니다.

![Untitled%2019.png](/images/2021-02-25/037/Untitled%2019.png)
- 구체적으로 취향의 유사도를 가중치로 사용한 평점의 가중 평균을 통해 평점을 추정한다.

![Untitled%2020.png](/images/2021-02-25/037/Untitled%2020.png)
- 앞서 설명한 방법을 통해, x가 아직 구매하지 않은 상품 각각에 대해 평점을 추정한다. 그리고 추정한 평점이 가장 높은 상품들을 x에게 추천한다.

### 장단점

- 장점
    - 상품에 대한 부가 정보가 없는 경우에도 사용할 수 있다.
- 단점
    - 충분한 수의 평점 데이터가 누적되어야 효과적이다.
    - 새 상품, 새로운 사용자에 대한 추천이 불가능하다.
    - 독특한 취향의 사용자에게 추천이 어렵다.

## 추천 시스템의 평가

- 추천 시스템의 평가의 방법은 다음과 같다.
    1. 데이터를 훈련 데이터와 평가 데이터로 분리한다.
    2. 평가 데이터를 비워 놓고 훈련 데이터를 이용해 평가 데이터를 추정한다.
    3. **추정한 평점과 실제 평가 데이터를 비교**하여 오차를 측정한다.

![Untitled%2021.png](/images/2021-02-25/037/Untitled%2021.png)
### 평가 지표

- 오차를 측정하는 지표로는 **평균 제곱 오차(Mean Squared Error, MSE)**가 많이 사용된다. 평가 데이터 내의 평점들의 집합을 T라고 한다. MSE는 아래 수식으로 계산한다.

![Untitled%2022.png](/images/2021-02-25/037/Untitled%2022.png)
- **평균 제곱근 오차(Root Mean Squared Error, RMSE)**도 많이 사용된다.

![Untitled%2023.png](/images/2021-02-25/037/Untitled%2023.png)
- 이 밖에도 다양한 지표가 사용된다.
    - 추정한 평점으로 순위를 매긴 후, 실제 평점으로 매긴 순위와의 상관계수를 계산
    - 추천한 상품 중 실제 구매로 이루어진 것의 비율을 측정하기도 한다.
    - 추천의 순서 혹은 다양성까지 고려하는 지표들도 사용된다.