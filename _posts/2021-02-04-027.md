---
title: 13일차 - CNN
tags: [boostcamp]
published: true
use_math: true
comments: true
---
# 13일차 - CNN

# RGB Image Convolution

- 인풋의 채널과 커널의 채널을 알면 아웃풋의 채널도 계산할 수 있다.

![Untitled.png](/images/2021-02-04/027/Untitled.png)
- CNN의 발전과정은 parameter를 줄이고, 딥하게 가는 방향으로 발전한다. 그래서 neural network를 볼 때 parameter를 파악하는 것이 중요하다.

## Stride

- stride는 convolution 연산을 할 때, 한 번 연산을 할 때 움직이는 거리를 의미한다.

![Untitled%201.png](/images/2021-02-04/027/Untitled%201.png)
## Padding

- 가장 자리를 연산하지 못하는 문제가 있기 때문에 이를 해결하기 위해 가장자리에 추가로 값을 덧대어 준다.

![Untitled%202.png](/images/2021-02-04/027/Untitled%202.png)
- 스트라이드와 패딩을 적절히 이용하면 출력값의 dimension을 입력값과 그대로 유지해줄 수 있다.

## Fully connected layer

![Untitled%203.png](/images/2021-02-04/027/Untitled%203.png)
- CNN의 마지막 레이어로 엄청난 parameter를 가지게 된다. 따라서 이 layer의 깊이는 줄이고 Convolution layer를 깊게 쌓는 것이 정석이다.

## 1x1 convolution

![Untitled%204.png](/images/2021-02-04/027/Untitled%204.png)
# Modern Convolutional Neural Networks

## AlexNet

- Rectified Linear Unit(ReLU) activation
- GPU implementation
- Local response normalization, Overlapping pooling
- Data augmentation
- Dropout

### ReLU

- Preserves propertis of lenear models
- Easy to optimize with gradient descent
- Good generalization
- Overcome the vanishing gradient problem

## VGGNet

- increasing depth with 3 * 3 convolution filters (with stride 1)
- 1*1 convolution for fully connected layers
- Dropout (p=0.5)

![Untitled%205.png](/images/2021-02-04/027/Untitled%205.png)
## GoogLeNet

### Inception Block

![Untitled%206.png](/images/2021-02-04/027/Untitled%206.png)
- Inception Block은 parameter의 개수를 줄여준다.
- 1 * 1 convolution은 채널 방향의 차원을 감소시킨다.

![Untitled%207.png](/images/2021-02-04/027/Untitled%207.png)
## ResNet

### Identity map

![Untitled%208.png](/images/2021-02-04/027/Untitled%208.png)
## DenseNet

### concatenation

![Untitled%209.png](/images/2021-02-04/027/Untitled%209.png)
- convolution으로 더하기 대신 concatenation해서 채널을 늘려주는 방식이다.
- 하지만 이럴 경우 parameter가 커질 수 있다.
- DenseNet은 Concatenation으로 채널을 늘리는 Dense Block과 1*1 convolution으로 채널을 줄이는 Transition Block으로 나뉜다.

# Computer Vision

## Fully Convolutional Network

![Untitled%2010.png](/images/2021-02-04/027/Untitled%2010.png)
- FCN 이후로는 아웃풋이 줄어들기 때문에 이를 늘려줄 필요가 있다.

## Deconvolution

![Untitled%2011.png](/images/2021-02-04/027/Untitled%2011.png)
## Dectection

### R-CNN

- 이미지 내에서 수없이 많은 region proposals를 뽑은 후 그것을 각각 AlexNet에 돌려서 분류하는 것이다.
- 하지만 이것은 너무 느리고 오래걸린다.

### SPPNet

- 이미지 전체에 대해서 CNN을 돌리고, bounding 된 영역에 대한 텐서만을 가지고와 분류한다.
- 한번만 CNN을 돌리기 때문에 R-CNN보다 빠르다.

### Fast R-CNN

- SPPNet와 상당히 비슷한 개념이다.
- 2000개 정도의 영역을 뽑는다.
- 이미지 전체에 대해 CNN을 돌린다.
- 각 영역에 대해 ROI pooling을 해 fixed length feature를 얻는다.
- 이 fixed length feature를 NN을 돌려 분류를 한다.

### Faster R-CNN

- Region proposals도 NN으로 뽑자는 것

**Region Proposal Network**

- k개의 Anchor box를 가지고 의미있을 만한 bounding box를 찾는 것

![Untitled%2012.png](/images/2021-02-04/027/Untitled%2012.png)
### YOLO

- Bounding box를 찾는 것과 그것에 대한 분류를 동시에 하는 것

![Untitled%2013.png](/images/2021-02-04/027/Untitled%2013.png)
- 결과적으로 다음과 같이 텐서의 크기가 결정된다.
- S * S : Number of cells of the grid
- B * 5 : B bounding boxes with offsets(x,y,w,h) and confidence
- C : Number of classes
- S * S * (B * 5 + C)
