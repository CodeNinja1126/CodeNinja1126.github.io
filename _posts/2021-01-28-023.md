---
title: 9일차 - AI를 위한 수학4 및 pandas2
tags: [boostcamp]
published: true
use_math: true
comments: true
---
# Groupby

![1.png](/images/2021-01-28/23/1.png)

- SQL groupby 명령어와 같다.
- split → apply → combine

```python
df.groupby('Team')['Points'].sum()
'''
Team
Devils    1536
Kings     3097
Riders    3049
Royals    1505
Name: Points, dtype: int64
'''

# hierarchical index
h_index = df.groupby(['Team','Year'])['Points'].sum()
'''
Team    Year
Devils  2014    863
        2015    673
Kings   2014    741
        2015    812
        2016    756
        2017    788
Riders  2014    876
        2015    789
        2016    694
        2017    690
Royals  2014    701
        2015    804
Name: Points, dtype: int64
'''

h_index.unstack()
'''
Year	2014	2015	2016	2017
Team				
Devils	863.0	673.0	NaN	NaN
Kings	741.0	812.0	756.0	788.0
Riders	876.0	789.0	694.0	690.0
Royals	701.0	804.0	NaN	NaN
'''

h_index.reset_index() # 인덱스 다시 붙여주기
'''
Team	Year	Points
0	Devils	2014	863
1	Devils	2015	673
2	Kings	2014	741
3	Kings	2015	812
4	Kings	2016	756
5	Kings	2017	788
6	Riders	2014	876
7	Riders	2015	789
8	Riders	2016	694
9	Riders	2017	690
10	Royals	2014	701
11	Royals	2015	804
'''

h_index.swaplevel()
'''
Year  Team  
2014  Devils    863
2015  Devils    673
2014  Kings     741
2015  Kings     812
2016  Kings     756
2017  Kings     788
2014  Riders    876
2015  Riders    789
2016  Riders    694
2017  Riders    690
2014  Royals    701
2015  Royals    804
Name: Points, dtype: int64
'''

# 정렬 메소드
h_index.sort_index(level=0) # level은 기준으로 할 인덱스를 결정
h_index.sort_values() # 값을 기준으로 정렬

# groupby된 객체는 시리즈이므로 시리즈 메소드 사용 가능
h_index.std(level=1)
'''
Year
2014    87.439026
2015    65.035888
2016    43.840620
2017    69.296465
Name: Points, dtype: float64
'''
```

- Groupby에 의해 Split된 상태를 추출 가능함

```python
grouped = df.groupby('Team')
list(grouped) # 이 때 grouped는 제네레이터이다.
'''
[('Devils',
       Team  Rank  Year  Points
  2  Devils     2  2014     863
  3  Devils     3  2015     673),
 ('Kings',
      Team  Rank  Year  Points
  4  Kings     3  2014     741
  5  Kings     4  2015     812
  6  Kings     1  2016     756
  7  Kings     1  2017     788),
 ('Riders',
        Team  Rank  Year  Points
  0   Riders     1  2014     876
  1   Riders     2  2015     789
  8   Riders     2  2016     694
  11  Riders     2  2017     690),
 ('Royals',
        Team  Rank  Year  Points
  9   Royals     4  2014     701
  10  Royals     1  2015     804)]
'''
# 이때 list안에 튜플은 ([Teams], [데이타프레임])의 형태이다.

grouped.get_group('Royals')
# grouped에서 그룹된 특정 데이타프레임 가져오기
```

## aggregation

- 그룹별로 연산을 적용해 데이터 프레임을 반환

```python
grouped.agg(sum)
'''
     Rank	Year	Points
Team			
Devils	5	4029	1536
Kings	9	8062	3097
Riders	7	8062	3049
Royals	5	4029	1505
'''

import numpy as np
grouped.agg(np.mean)
'''
        Rank	Year	Points
Team			
Devils	2.50	2014.5	768.00
Kings	2.25	2015.5	774.25
Riders	1.75	2015.5	762.25
Royals	2.50	2014.5	752.50
'''

grouped['Points'].agg([np.mean, np.sum, np.std])
'''
            mean	sum	std
Team			
Devils	768.00	1536	134.350288
Kings	774.25	3097	31.899582
Riders	762.25	3049	88.567771
Royals	752.50	1505	72.831998
'''
```

## Transformation

- 그룹별로 연산을 할 수 있게 해준다

```python
score = lambda x: x.max()
groubed.transform(score)
'''
  Rank	Year	Points
0	2	2017	876
1	2	2017	876
2	3	2015	863
3	3	2015	863
4	4	2017	812
5	4	2017	812
6	4	2017	812
7	4	2017	812
8	2	2017	876
9	4	2015	804
10	4	2015	804
11	2	2017	876
'''
# 그룹된 상태에서 각 column에 함수를 적용함
```

## Filter

- 특정 조건으로 데이터를 검색할 때 사용

```python
df.groupby('Teams').filter(lambda x: len(x) >= 3)
'''
  Team	Rank	Year	Points
0	Riders	1	2014	876
1	Riders	2	2015	789
4	Kings	3	2014	741
5	Kings	4	2015	812
6	Kings	1	2016	756
7	Kings	1	2017	788
8	Riders	2	2016	694
11	Riders	2	2017	690
'''
df.groupby('Team').filter(lambda x: x['Points'].mean() > 770)
'''
   Team	Rank	Year	Points
4	Kings	3	2014	741
5	Kings	4	2015	812
6	Kings	1	2016	756
7	Kings	1	2017	788
'''
```

# Pivot Table

- 우리가 엑셀에서 사용하던 그 것이다.
- index 축은 groupby와 동일
- column에 labeling을 추가해 aggregation을 하는것

```python
df_phone.pivot_table(['duration'],
                      index=[df_phone.month, df_phone.item],
                      columns=df_phone.network, aggfunc='sum',
                      fill_value=0)
```

![2.png](/images/2021-01-28/23/2.png)

## Crosstab

- 두 칼럼에 교차 빈도, 비율, 덧셈 등을 구할 때 사용
- Pivot table의 특수한 형태이다.
- User_Item Rating Matrix 등을 만들 때 사용가능함

```python
pd.crosstab(
    index=[df_phone.month, df_phone.item],
    columns=df_phone.network,
    values=df_phone.duration,
    aggfunc='sum'
).fillna(0)
```

![3.png](/images/2021-01-28/23/3.png)

# Merge & Concat

## Merge

- SQL에서 많이 사용하는 Merege와 같은 기능
- 두 개의 데이터를 하나로 합침

```python
pd.merge(df_a, df_b, on='subject_id')
# on에는 공통 인덱스

pd.merge(df_a, df_b, left_on='left_id', right_on='right_id')
# 기준으로 할 인덱스의 이름이 다르면
# left_on, right_on에 각 인덱스 이름을 넘겨준다.
```

## join method

![4.png](/images/2021-01-28/23/4.png)

```python
pd.merge(df_a, df_b, on='subject_id', how='inner')
'''
디폴트 join이다.
공통 인덱스가 존재하는 값만 join한다.
'''
pd.merge(df_a, df_b, on='subject_id' how='left')
'''
left join 또는 right join이다.
각 왼쪽 오른쪽 테이블의 인덱스를 기준으로 join한다.
인덱스에 해당하는 값이 없으면 NaN을 채워준다.
'''
pd.merge(df_a, df_b, on='subject_id', how='outer')
'''
모든 값을 join한다. 없는 값은 NaN으로 채운다.
'''
pd.merge(df_a, df_b, right_index=True, left_index=True)
'''
데이터 프레임 저장 순서를 기준으로 하는 merge이다.
이렇게 하면 왼쪽 오른쪽 인덱스가 모두 살아있게 된다.
'''
```

## Concat

- 같은 형태의 데이터프레임을 붙이는 함수

```python
pd.concat([df_a, df_b])

df_a.append(df_b)
'''
concat와 같은 기능을 한다.
이때 주의해야 할 점은 두 데이터프레임의 
column이 같아야 한다는 것이다.
'''

pd.concat([df_a, df_b], axis=1)
'''
원하는 축방향으로도 붙일 수 있다.
'''
```

## DB 불러오기

```python
import sqlite3

conn = sqlite3.connect([db 주소])
cur = conn.cursor()
cur.excute([쿼리 문])
results = cur.fetchall()

df = pd.read_spl_query([쿼리 문], conn)
# db에서 가져온 데이터로 데이터프레임 생성
```

## XLS persistence

- Xls엔진으로 openpyxls 또는 XlsxWrite 사용(설치해야되는 모듈)

```python
writer = pd.ExcelWriter([저장할 xlsx 이름 및 주소],
                        engine = 'xlsxwriter')
df_routes.to_excel(writer, sheet_name = 'Sheet1')

pd.read_excel('파일명')
# 엑셀에서 파일 읽어오기
```

## Pickle persistence

```python
df.to_pickle([저장할 pickle 이름 및 주소])
# 저장
df = pd.read_pickle([pickle 주소])
# 읽어오기
```

# 확률론 맛보기

- 딥러닝은 **확률론 기반의 기계학습 이론**에 바탕을 두고 있다.
- 기계학습에서 사용되는 손실함수들의 작동원리는 데이터 공간을 통계적으로 해석해서 유도한다.
- 회귀 분석에서 손실함수로 사용되는 L-2노름은 **예측오차의 분산을 가장 최소화하는 방향으로 학습하도록 유도**한다**.**
- 분류 문제에서 사용되는 **교차 엔트로피(corss-entropy)**는 **모델 예측의 불확실성을 최소화하는 방향으로 학습하도록 유도**한다.
- 분산 및 불확실성을 **최소화하기 위해서는 측정하는 방법**을 알아야 한다.

## 확률 분포

- 데이터 공간을 $\mathscr X * \mathscr Y$라 표기하고 $\mathscr D$는 데이터공간에서 데이터를 추출하는 분포이다.
- 데이터는 확률변수로 $(x,y)\sim\mathscr D$라 표기한다.
- 결합분포 $P(x, y)$는  $\mathscr D$를 모델링한다.
- $P(X)$는 입력 $x$에 대한 **주변확률분포**이며 $y$에 대한 정보를 주진 않는다.
- 다음과 같은 방법으로 주변확률분포를 구할 수 있다.

![5.png](/images/2021-01-28/23/5.png)

- **조건부확률분포** $P(x|y)$는 데이터 공간에서 입력 $x$와 출력 $y$ 사이의 관계를 모델링한다.

## 이산확률변수 vs 연속확률변수

- 확률 변수는 확률분포 $\mathscr D$에 따라 **이산형(discrete)**과 **연속형(continuous)**확률변수로 구분하게 된다.

![6.png](/images/2021-01-28/23/6.png)

- 모든 확률 변수가 이 두가지로 구분되는 것은 아니다.

## 조건부확률과 기계학습

- 조건부확률 $P(y|x)$는 입력변수 $x$에 대해 정답이 $y$일 확률을 의미한다.
- 로지스틱 회귀에서 사용했던 선형모델과 소프트맥스 함수의 결합은 **데이터에서 추출된 패턴을 기반으로 확률을 해석**하는데 사용된다.
- 분류 문제에서 $softmax(W\phi + b)$는 데이터 $x$로부터 추출된 특징패턴$\phi(x)$와 가중치행렬 $W$를 통해 조건부확률 $P(y|x)$를 계산한다.
- 회귀 문제의 경우 조건부기대값 $\mathbb E[y|x]$를 추정한다.

![7.png](/images/2021-01-28/23/7.png)

- 조건부기대값은 $**\mathbb E\|y - f(x)\|_2$을 최소화하는 함수 $f(x)$와 일치**한다.
- 딥러닝은 다층신경망을 사용하여 데이터로부터 특징패턴 $\phi$를 추출한다.
- 특징패턴을 학습하기 위해 어떤 손실함수를 사용할지는 기계학습 문제와 모델에 의해 결정된다.

## 기대값

- 확률분포가 주어지면 데이터를 분석하는 데 사용 가능한 여러 종류의 **통계적 범함수(statistical functional)를 계산**할 수 있다.
- **기대값(expectation)은 데이터를 대표하는 통계량**이면서 동시에 확률분포를 통해 다른 통계적 범함수를 계산하는데 사용

![8.png](/images/2021-01-28/23/8.png)

- 기대값을 이용해 분산, 첨도, 공분산 등 여러 통계량을 계산할 수 있다.

## 몬테카를로 샘플링

- 기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분이다.
- 확률분포를 모를 때 **데이터를 이용해 기대값을 계산하려면 몬테카를로(Monte Carlo)샘플링 방법**을 사용한다.
- 몬테카를로는 이산형이든 연속형이든 상관없이 성립한다.
- 샘플링된 데이터를 목적함수에 대입하고 산술평균을 계산해주면 우리가 구하려는 기대값에 근사하게 된다.

![9.png](/images/2021-01-28/23/9.png)
