I"A<h1 id="17일차---rnn-기본">17일차 - RNN 기본</h1>

<h1 id="basics-of-recurrent-neural-networks-rnns">Basics of Recurrent Neural Networks (RNNS)</h1>

<p><img src="/images/2021-02-17/031/Untitled.png" alt="Untitled.png" /></p>
<ul>
  <li>RNN의 기본 구조는 현재 $t$에서 이전의 값 $h_t$를 사용한다는 것이 가장 큰 특징이다.</li>
  <li>이를 통해 RNN은 시퀀스 데이터를 학습할 수 있게 된다.</li>
</ul>

<h2 id="how-to-calculate-the-hidden-state-of-rnns">How to calculate the hidden state of RNNs</h2>

<p><img src="/images/2021-02-17/031/Untitled%201.png" alt="Untitled%201.png" /></p>
<ul>
  <li>위와 같은 함수를 통해 한번의 스텝을 계산한다.</li>
  <li>이 때 매 스텝마다 함수와 함수의 파라미터들은 바뀌지 않는다는 것을 명심하라.</li>
</ul>

<p><img src="/images/2021-02-17/031/Untitled%202.png" alt="Untitled%202.png" /></p>
<ul>
  <li>함수는 위와 같다. $\tanh()$는 활성함수이다. 그리고 각 $W_{hh}$ 와 $W_{xh}$의 의미는 다음과 같다.</li>
</ul>

<p><img src="/images/2021-02-17/031/Untitled%203.png" alt="Untitled%203.png" />
<img src="/images/2021-02-17/031/Untitled%204.png" alt="Untitled%204.png" /></p>
<ul>
  <li>$W_{xh}, W_{hh}$는 $x_t, h_{t-1}$를 $h_{t}$로 보내주는 역할을 한다.</li>
</ul>

<h2 id="types-of-rnns">Types of RNNs</h2>

<h3 id="one-to-one">One-to-one</h3>

<p><img src="/images/2021-02-17/031/Untitled%205.png" alt="Untitled%205.png" /></p>
<ul>
  <li>일반적인 형태의 신경망을 말한다.</li>
</ul>

<h3 id="one-to-many">One-to-many</h3>

<p><img src="/images/2021-02-17/031/Untitled%206.png" alt="Untitled%206.png" /></p>
<ul>
  <li>입력은 한번만 하고 여러 개의 아웃풋을 얻는 경우, 이 때는 정말로 매번 입력이 없는 것이 아니고 0으로 채워진 벡터 혹은 매트릭스를 입력한다.</li>
</ul>

<h3 id="many-to-one">Many-to-one</h3>

<p><img src="/images/2021-02-17/031/Untitled%207.png" alt="Untitled%207.png" /></p>
<ul>
  <li>모든 입력이 끝난 후 마지막에 한번만 아웃풋을 하는 경우, 예로는 문장의 감정 상태를 파악하는 모델에 사용될 수 있다.</li>
</ul>

<h3 id="many-to-many">Many-to-many</h3>

<p><img src="/images/2021-02-17/031/Untitled%208.png" alt="Untitled%208.png" /></p>
<ul>
  <li>모든 시퀀스 데이터를 입력하고 난 후 다시 시퀀스 형태로 데이터를 받는 경우, 이 때 데이터는 입력이 끝난 후 출력된다. 예로는 기계 번역이 있다.</li>
</ul>

<p><img src="/images/2021-02-17/031/Untitled%209.png" alt="Untitled%209.png" /></p>
<ul>
  <li>시퀀스 데이터를 받아 리얼 타임으로 아웃풋을 받아야 할 때 사용한다. 대표적으로는 프레임 레벨의 영상 분류가 있다.</li>
</ul>

<h2 id="character-level-language-model">Character-level Language Model</h2>

<ul>
  <li>‘hello’라는 단어를 예를 들어보자.</li>
</ul>

<p><img src="/images/2021-02-17/031/Untitled%2010.png" alt="Untitled%2010.png" /></p>
<ul>
  <li>이 때 소프트 맥스 함수를 통해 $W_{hy}$를 학습시키게 될 것이다.</li>
  <li>예측값을 NLP의 입력으로 사용해 첫 한개의 입력으로 시퀀스 데이터를 예측할 수 있다.</li>
  <li>캐릭터레벨로 학습시킬 경우 공백, 줄바꿈문자, 맞춤표까지 의미가 크므로 모두 학습에 사용한다.</li>
  <li>이렇게 논문, 문학, 코드 등을 학습시키면, 그 특징을 그럴듯하게 학습해낸다.</li>
  <li>이 때 처음부터 첫 글자만을 입력으로 사용해서 학습시키게 되면 학습속도가 매우 더디므로, Teach Forcing이라는 기법을 사용해 정답레이블을 인풋에 넣어주게 된다.</li>
</ul>

<h2 id="backpropagation-through-time-bptt">Backpropagation through time (BPTT)</h2>

<p><img src="/images/2021-02-17/031/Untitled%2011.png" alt="Untitled%2011.png" /></p>
<ul>
  <li>RNN의 역전파는 현재 아웃풋의 로스를 계산하기 위해서는 이전 시퀀스를 모두 계산해야 하므로 매우 많은 연산 자원이 필요하다.</li>
</ul>

<p><img src="/images/2021-02-17/031/Untitled%2012.png" alt="Untitled%2012.png" /></p>
<ul>
  <li>그래서 일정 크기로 전체 시퀀스를 잘라 그 안에서만 역전파와 순전파를 진행한다.</li>
</ul>

<p><img src="/images/2021-02-17/031/Untitled%2013.png" alt="Untitled%2013.png" />
<img src="/images/2021-02-17/031/Untitled%2014.png" alt="Untitled%2014.png" /></p>
<ul>
  <li>$h$벡터의 특정 위치의 값이 음수와 양수 상태일 때를 시각화한 것으로 특정 셀이 이전의 상태를 보존하고 있음을  알 수 있다.</li>
</ul>

<h2 id="vanishingexploding-gradient-problem-in-rnn">Vanishing/Exploding Gradient Problem in RNN</h2>

<p><img src="/images/2021-02-17/031/Untitled%2015.png" alt="Untitled%2015.png" /></p>
<ul>
  <li>바닐라 RNN의 경우에는 계속해서 $W_{hh}$를 곱해주므로 그래디언트가 너무 커지거나 작아져 버리는 문제점이 존재한다.</li>
</ul>

<h1 id="long-short-term-memorylstm">Long Short-Term Memory(LSTM)</h1>

<ul>
  <li>어떠한 변환없이 쭉 전달되는 셀 스테이트를 넘긴다.</li>
  <li>이를 통해 긴 스텝 이후의 의존도 문제를 해결한다.</li>
</ul>

<p><img src="/images/2021-02-17/031/Untitled%2016.png" alt="Untitled%2016.png" />
<img src="/images/2021-02-17/031/Untitled%2017.png" alt="Untitled%2017.png" /></p>
<ul>
  <li>이때 $\tanh$는 정보의 변환을, $\sigma$는 정보의 비율을 결정하기 위한 함수라고 생각하면 된다.</li>
</ul>

<h3 id="gate-gate">Gate gate</h3>

<p><img src="/images/2021-02-17/031/Untitled%2018.png" alt="Untitled%2018.png" /></p>
<ul>
  <li>이전까지의 정보를 담고 있는 $C_{t-1}$을 얼마나 기억할 것인 지를 결정하는 게이트</li>
</ul>

<h3 id="gate-gate-1">Gate gate</h3>

<p><img src="/images/2021-02-17/031/Untitled%2019.png" alt="Untitled%2019.png" /></p>
<ul>
  <li>현재의 정보를 얼마나 담을 것 인지를 결정하는 게이트</li>
</ul>

<h3 id="output-gate">Output gate</h3>

<p><img src="/images/2021-02-17/031/Untitled%2020.png" alt="Untitled%2020.png" /></p>
<ul>
  <li>$h_t$의 값을 결정하는 게이트, 이 때 $h_t$는 미래의 시퀀스에 장기적인 영향력을 주는 것이 아니라 다음 시퀀스의 예측에 직접적으로 영향을 주는 값이다.</li>
</ul>

<h1 id="gated-recurrent-unitgru">Gated Recurrent Unit(GRU)</h1>

<p><img src="/images/2021-02-17/031/Untitled%2021.png" alt="Untitled%2021.png" /></p>
<ul>
  <li>인풋 게이트인 $z_t$를 이용해  현재의 정보인 $\tilde{h_t}$ 와 과거의 정보인 $h_t$의 조합 비율을 결정한다.</li>
  <li>LSTM과 GRU는 이전의 정보를 전달하는데 곱셈을 사용하지 않고 덧셈을 사용하면서 그래디언트를 과거로부터 잘 전달할 수 있게 되었다.</li>
</ul>
:ET