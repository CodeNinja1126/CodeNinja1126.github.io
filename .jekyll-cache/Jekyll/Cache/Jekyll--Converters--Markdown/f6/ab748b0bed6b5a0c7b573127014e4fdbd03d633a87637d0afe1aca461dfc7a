I"i<h1 id="베이즈-통계학">베이즈 통계학</h1>

<ul class="task-list">
  <li>
    <p>조건부 확률 $P(A\mid B)$는 B라는 사건이 일어났을 때 A 사건이 일어날 확률</p>
  </li>
  <li>
    <p>$P(A\cap B) = P(B)P(A\mid B)$</p>
  </li>
  <li>
    <p>A라는 새로운 정보가 주어졌을 때 $P(B)$로부터 $P(B\mid A)$를 계산하는 방법을 제공한다.</p>
  </li>
  <li>
    <p>$P(B\mid A) = \dfrac {P(A\cap B)} {P(A)} = P(B) \dfrac {P(A\mid B)} {P(A)}$</p>
  </li>
  <li>
    <p>베이즈 정리는 조건부확률을 이용하여 <strong>정보를 갱신하는 방법</strong>을 알려준다.</p>
  </li>
  <li class="task-list-item">
    <p><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />모수란?</p>
  </li>
</ul>

<p>모수는 모집단의 특성(모평균, 모분산 등)을 나타내는 값이다. 이 값은 모집단을 전수조사해야만 알 수 있는 값이다. 그러나 실질적으로 모집단이 워낙 방대하므로 표본을 조사해 표본평균, 표본분산 등으로 모평균, 모분산 등을 추정할 수 있다.</p>

<p><img src="/images/2021-02-02/25/Untitled.png" alt="Untitled.png" /></p>
<ul>
  <li>사후확률 : <strong>데이터를 측정한 이후</strong>의 확률</li>
  <li>사전확률 : <strong>데이터가 주어지지 않은 상황</strong>에서 모델링을 하기 이전에 사전에 주어진 확률</li>
</ul>

<p>사전 확률로부터 시작해 데이터를 측정하면서 베이즈 정리를 통해 확률을 업데이트할 수 있다.</p>

<ul>
  <li>가능도 : 현재의 가정(모수 혹음 패러미터)에서 데이터가 관측될 확률</li>
  <li>evidence : 데이터 전체의 분포</li>
  <li>베이즈 통계학에서는 사전확률이 상당히 중요한 정보이다. 만약 사전확률이 없을 경우, 임의값을 사용하기도 하지만 이는 분석의 신뢰도가 매우 떨어지는 결과를 낳을 수 있다.</li>
</ul>

<h2 id="베이즈-정리-예제">베이즈 정리: 예제</h2>

<p><img src="/images/2021-02-02/25/Untitled%201.png" alt="Untitled%201.png" /></p>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />$¬$은 not을 의미한다. 즉 $P(\mathscr D\mid ¬\theta)$은 $\theta$가 일어나지 않았을 경우, $\mathscr D$가 일어났을 확률을 이야기 한다.</li>
  <li class="task-list-item">오탐률이 오르면 테스트의 정밀도가 떨어진다.</li>
</ul>

<h2 id="조건부-확률의-시각화">조건부 확률의 시각화</h2>

<p><img src="/images/2021-02-02/25/Untitled%202.png" alt="Untitled%202.png" /></p>
<ul>
  <li>일반적으로 2종 오류의 경우 심각한 문제를 야기하는 경우가 많기 때문에 1종 오류에서 희생을 보더라도 2종 오류를 줄이는 쪽으로 설계를 많이 한다.</li>
</ul>

<h2 id="베이즈-정리를-통한-정보의-갱신">베이즈 정리를 통한 정보의 갱신</h2>

<ul>
  <li>베이즈 정리를 통해 새로운 데이터가 들어왔을 때 앞서 계산한 사후확률을 사전확률로 사용하여 갱신된 사후확률을 계산할 수 있다.</li>
</ul>

<p><img src="/images/2021-02-02/25/Untitled%203.png" alt="Untitled%203.png" /></p>
<ul>
  <li>새로운 데이터가 들어왔을 때는 앞서 계산한 사후확률을 사전확률로 사용하고, evidence를 계산해 사후확률을 계산한다.</li>
  <li>베이즈 정리의 장점은 새롭게 들어온 데이터를 이용해 정보를 업데이트할 수 있는 것에 있다.</li>
</ul>

<h2 id="조건부확률--인과관계">조건부확률 → 인과관계</h2>

<ul>
  <li>조건부 확률은 유용한 통계적 해석을 제공하지만 인과관계(causality)를 추론할 때 함부로 사용해서는 안된다. 데이터가 많아져도 조건부확률만으로는 인과관계를 예측할수는 없다.</li>
  <li>인과관계는 데이터 분포의 변화에 강건한 예측모형을 만들 때 필요하다.</li>
  <li>조건부확률 기반의 예측모형은 새로운 유형의 데이터에 민감하게 정확도가 떨어질 수 있다.</li>
  <li>인과관계만 고려해서는 높은 예측정확도를 보장할 수 없다. 하지만 다양한 시나리오에 정확도가 민감하게 변하지 않는다.</li>
  <li>중첩 요인(confounding factor)의 효과를 제거하고 원인에 해당하는 변수만의 인과관계를 계산해야 한다. 만일 중첩요인의 효과를 제거하지 않으면 가짜 연관성(spurious correlation)이 나온다.</li>
</ul>

<h2 id="인과관계-추론-예제">인과관계 추론: 예제</h2>

<p><img src="/images/2021-02-02/25/Untitled%204.png" alt="Untitled%204.png" /></p>
<h1 id="deep-learning-basic">Deep Learning Basic</h1>

<h2 id="key-components-of-deep-learning">key components of deep learning</h2>

<ul>
  <li>The <strong>Data</strong> that the model can learn form</li>
  <li>The <strong>Model</strong> how to transform the data</li>
  <li>The <strong>Loss</strong> function that quantifies the badness of the model</li>
  <li>The <strong>Algorithm</strong> to adjust the parameters to minimize the loss</li>
</ul>

<h1 id="pytorch">Pytorch</h1>

<ul>
  <li>Numpy 구조를 가지는 Tensor 객체로 array 표현</li>
  <li>자동미분을 지원하여 DL 연산을 지원</li>
  <li>다양한 형태의 DL을 지원하는 함수와 모델을 지원한다.</li>
</ul>

<h1 id="neural-networks">Neural Networks</h1>

<ul>
  <li>인간의 신경망에 영향을 받아 만든 컴퓨터 시스템이다.</li>
  <li>Neural networks are function approximators that stack affine transformations followed by nonlinear transformations.</li>
</ul>

<h1 id="further-homework">Further homework</h1>

<p>noMNIST를 주어진 파이토치 코드를 이용해 학습시켜보기</p>

<p>데이터셋: <a href="http://yaroslavvb.com/upload/notMNIST/">http://yaroslavvb.com/upload/notMNIST/</a></p>
:ET