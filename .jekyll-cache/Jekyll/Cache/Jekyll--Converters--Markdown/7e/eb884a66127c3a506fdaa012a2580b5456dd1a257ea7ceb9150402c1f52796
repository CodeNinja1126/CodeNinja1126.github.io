I"<h1 id="15일차---generative-models">15일차 - Generative Models</h1>

<h1 id="learning-a-generative-models">Learning a Generative Models</h1>

<ul>
  <li>Generative Model은 단순히 생성을 하는 모델만을 말하는 것은 아니다.</li>
  <li>Generative Model은 생성과 함께 생성된 결과에 대해 구별하는 기능을 포함한다.</li>
  <li>어떠한 결과물에 대해서 $p(x)$를 얻어낼 수 있는 모델을 explicit model이라 한다. 그리고 그렇지 않은 모델을 implicit 모델이라고 한다.</li>
  <li>$p(x)$가 커지면 의도한 결과물에 가까울 것이고 작다면 그렇지 않을 것이다. (anomaly detection, 이상행동 감지)</li>
  <li>Unsupervised representation learning 에서 사용되는 feature learning도 Generative model이라 보는 시각도 존재한다.</li>
</ul>

<h2 id="basic-discrete-distribution">Basic Discrete Distribution</h2>

<p><img src="/images/2021-02-14/Untitled.png" alt="Untitled.png" /></p>
<h3 id="example">Example</h3>

<ul>
  <li>n개의 픽셀을 가진 바이너리 이미지를 생각해보자</li>
  <li>이때 나올수 있는 상태 가지수는 $2^n$이다.</li>
  <li>이 때 우리가 각 상태를 특정할 수 있는 parameter는 총 $2^n - 1$이다.</li>
  <li>반면 우리가 이 때 각 픽셀에 대해 독립적인 사건으로 생각해 보자.</li>
  <li>이 때 나올 수 있는 상태 가지수는 $2^n$으로 같다.</li>
  <li>하지만 이 때의 parameter은 총 n이다.</li>
</ul>

<h3 id="conditional-indipendence">Conditional indipendence</h3>

<p><img src="/images/2021-02-14/Untitled%201.png" alt="Untitled%201.png" /></p>
<ul>
  <li>위의 체인 룰을 가지고 다음과 같이 식을 만들 수 있다.</li>
</ul>

<p><img src="/images/2021-02-14/Untitled%202.png" alt="Untitled%202.png" /></p>
<ul>
  <li>이 경우 여전히 Parameter은 여전히 $2^n - 1$이다.</li>
</ul>

<p><img src="/images/2021-02-14/Untitled%203.png" alt="Untitled%203.png" /></p>
<ul>
  <li>하지만 이렇게 Markov 가정을 이용하면 parameter를 줄일 수 있게 된다.</li>
  <li>이렇게 parameter를 대폭 줄이면서도 어느 정도 입력 간에 의존적인 상태를 유지할 수 있게 된다.</li>
</ul>

<h2 id="auto-regressive-model">Auto-regressive model</h2>

<ul>
  <li>Conditional indipendence을 활용하는 모델이다.</li>
  <li>우리는 $p(x)$를 학습시키는 것이 목적이다.</li>
  <li>이 값을 체인룰을 통해 식을 길게 전개한다.</li>
  <li>우리는 임의의 값에 대해 순서를 정해야 한다. 예를 들어 이미지의 경우 가로 방향 세로 방향 대각선 방향 등으로 순서를 정할 수 있다.</li>
</ul>

<h3 id="nade--neural-autoregressive-density-estimator">NADE : Neural Autoregressive Density Estimator</h3>

<p><img src="/images/2021-02-14/Untitled%204.png" alt="Untitled%204.png" /></p>
<ul>
  <li>NADE는 주어진 입력에 대해 확률을 계산할 수 있는 explicit 모델이다.</li>
  <li>주어진 이미지에 대해서 각 픽셀의 확률을 계산하는 것은 체인룰로 $p(x)$를 전개하고 모든 값을 곱하는 것이다.</li>
  <li>연속 확률 변수를 모델링하는 경우, 가우시안 혼합 모델을 사용할 수 있다.</li>
  <li>참조 <a href="https://untitledtblog.tistory.com/133">https://untitledtblog.tistory.com/133</a></li>
</ul>

<h2 id="pixel-rnn">pixel RNN</h2>

<ul>
  <li>auto-regressive model을 정의하기 위해 RNN을 사용할 수도 있다.</li>
</ul>

<p><img src="/images/2021-02-14/Untitled%205.png" alt="Untitled%205.png" /></p>
<ul>
  <li>체인의 순서에 기반한 pixel RNN에는 다음과 같은 두가지 모델이 있다.</li>
</ul>

<p><img src="/images/2021-02-14/Untitled%206.png" alt="Untitled%206.png" /></p>
<h1 id="latent-variable-models">Latent Variable Models</h1>

<ul>
  <li>Is an <strong>autoencoder</strong> a generative model?</li>
  <li>Latent Variable Model은 implicit 모델이다.</li>
</ul>

<h3 id="variational-auto-encoder">Variational Auto-encoder</h3>

<ul>
  <li><strong>Variational inference(VI)</strong></li>
  <li>VI의 목적은 <strong>posterior distribution</strong>을 가장 잘 매칭시키는 <strong>variational distribution</strong>을 최적화하는 것이다.</li>
  <li><strong>Posterior distribution</strong>: $p_\theta(z\mid x)$</li>
  <li><strong>Variational distribution</strong>: $q_\phi(z \mid x)$</li>
  <li>특히 우리는 KL divergence를 사용하여 실제 Posterior와의 거리를 최소화하는 Variantional distribution를 찾고 싶다.</li>
</ul>

<p><img src="/images/2021-02-14/Untitled%207.png" alt="Untitled%207.png" /></p>
<ul>
  <li>하지만 우리는 Posterior가 무엇인지도 모르는데 어떻게 Variantional distribution을 찾을 것인가</li>
</ul>

<p><img src="/images/2021-02-14/Untitled%208.png" alt="Untitled%208.png" /></p>
<ul>
  <li>ELBO(evidence lower bound)를 이용할 수 있다.</li>
  <li>참조 <a href="https://hugrypiggykim.com/2018/09/07/variational-autoencoder%EC%99%80-elboevidence-lower-bound/">https://hugrypiggykim.com/2018/09/07/variational-autoencoder와-elboevidence-lower-bound/</a></li>
</ul>

<p><img src="/images/2021-02-14/Untitled%209.png" alt="Untitled%209.png" /></p>
<h3 id="variational-auto-encoder의-주요-한계">Variational Auto-encoder의 주요 한계</h3>

<p><img src="/images/2021-02-14/Untitled%2010.png" alt="Untitled%2010.png" /></p>
<h3 id="adversarial-auto-encoder">Adversarial Auto-encoder</h3>

<p><img src="/images/2021-02-14/Untitled%2011.png" alt="Untitled%2011.png" /></p>
<h1 id="gangenerative-adversarial-network">GAN(Generative Adversarial Network)</h1>

<p><img src="/images/2021-02-14/Untitled%2012.png" alt="Untitled%2012.png" />
<img src="/images/2021-02-14/Untitled%2013.png" alt="Untitled%2013.png" /></p>
<ul>
  <li>GAN은 생성과 분류를 번갈아 가며 학습한다. 생성을 하면 그것을 진짜 이미지와 섞어 분류를 학습시키고, 다시 그것을 기반으로 생성을 학습시킨다. 이를 계속 반복한다.</li>
</ul>

<p><img src="/images/2021-02-14/Untitled%2014.png" alt="Untitled%2014.png" />
<img src="/images/2021-02-14/Untitled%2015.png" alt="Untitled%2015.png" /></p>
<ul>
  <li>결과적으로 GAN은 discrimainator와 generator 사이의 JSD를 최소화시키는 모델이라 할 수 있다</li>
  <li>GAN역시 implicit 모델이다.</li>
</ul>
:ET