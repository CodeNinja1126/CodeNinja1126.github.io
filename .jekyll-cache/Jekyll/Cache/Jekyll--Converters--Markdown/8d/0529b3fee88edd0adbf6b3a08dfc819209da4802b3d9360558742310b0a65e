I"<<h1 id="군집-탐색">군집 탐색</h1>

<h1 id="군집-구조와-군집-탐색-문제">군집 구조와 군집 탐색 문제</h1>

<ul>
  <li>군집(Communitiy)는 자음 조건들을 만족하는 정점들의 집합이다.
    <ol>
      <li>집합에 속하는 정점 사이에는 많은 간선이 존재한다.</li>
      <li>집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재한다.</li>
    </ol>
  </li>
  <li>‘많은’ 혹은 ‘적은’ 이란 애매한 표현이 사용되므로 수학적으로 엄밀한 정의는 아니다.</li>
</ul>

<h2 id="실제-그래프에서의-군집들">실제 그래프에서의 군집들</h2>

<ul>
  <li>온라인 소셜 네트워크의 군집들은 사회적 무리를 의미하는 경우가 많다.
    <ul>
      <li>온라인 소셜 네트워크의 군집들이 부정 행위와 연관된 경우도 있다.
        <ul>
          <li>ex) 팔로우 수를 늘려주는 등의 부정 행위</li>
        </ul>
      </li>
      <li>조직 내 분란이 소셜 네트워크 상의 군집으로 표현된 경우도 있다.</li>
      <li>키워드 - 광고주 그래프에서는 동일한 주제의 키워드들이 군집을 형성한다.</li>
    </ul>
  </li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled.png" alt="Untitled.png" /></p>
<ul>
  <li>뉴런간 연결 그래프에서는 군집들이 뇌의 기능적 구성 단위를 의미한다.</li>
</ul>

<h2 id="군집-탐색-문제">군집 탐색 문제</h2>

<ul>
  <li>그래프를 여러 군집으로 ‘잘’ 나누는 문제를 군집 탐색(Community Detection) 문제라고 한다.</li>
  <li>보통은 각 정점이 한 개의 군집에 속하도록 군집을 나눈다. 비지도 기계학습 문제인 클러스터링(Clusterting)와 상당히 유사하다.</li>
  <li>이를 잘 풀기 위해선 먼저 <strong>성공적인 군집 탐색</strong>이 무엇인지를 정의할 필요가 있다.</li>
</ul>

<h1 id="군집-구조의-통계적-유의성과-군집성">군집 구조의 통계적 유의성과 군집성</h1>

<h2 id="배치-모형configuration-model">배치 모형(Configuration Model)</h2>

<p><img src="/images/2021-02-25/037/Untitled%201.png" alt="Untitled%201.png" /></p>
<ul>
  <li>배치 모형에서 임의의 두 정점 $i$와 $j$ 사이에 간선이 존재할 확률은 두 정점의 연결성에 비례한다.</li>
</ul>

<h2 id="군집성modularity">군집성(Modularity)</h2>

<p><img src="/images/2021-02-25/037/Untitled%202.png" alt="Untitled%202.png" /></p>
<ul>
  <li>이 때 배치모형은 기댓값을 사용하는 이유는 배치 모형이 무작위성을 가지기 때문이다.</li>
  <li>즉 배치 모형과 비교했을 때, 그래프에서 군집 내부 간선의 수가 월등히 많을수록 성공한 군집 탐색이다.</li>
  <li>군집성은 항상 -1과 +1 사이의 값을 갖는다. 일반적으로 0.3 ~ 0.7 정도의 군집성을 가지면 통계적으로 유의미한 군집들을 찾아냈다고 할 수 있다.</li>
</ul>

<h1 id="군집-탐색-알고리즘">군집 탐색 알고리즘</h1>

<h2 id="girvan-newman-알고리즘">Girvan-Newman 알고리즘</h2>

<ul>
  <li>대표적인 Top-Down 방식의 알고리즘이다.</li>
  <li>전체 그래프에서 탐색을 시작하여 군집들이 서로 분리되도록, 간선을 순차적으로 제거한다.</li>
  <li>이 때 서로 다른 군집을 연결하는 다리 역할의 간선을 제거한다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%203.png" alt="Untitled%203.png" /></p>
<ul>
  <li>다리 역할의 간선을 찾아내는 것은 <strong>매개 중심성(Betweeness Centrality)</strong>을 사용한다. 이는 해당 간선이 <strong>정점 간의 최단 경로에 놓이는 횟수</strong>를 의미한다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%204.png" alt="Untitled%204.png" /></p>
<ul>
  <li>매개 중심성이 높은 간선들이 다른 군집을 연결하는 다리 역할을 하는 것을 알 수 있다.</li>
  <li>Girvan-Newman 알고리즘은 매개 중심성이 높은 간선을 순차적으로 제거한다. 그리고 간선이 제거될 때마다, 매개 중심성을 다시 계산하여 갱신한다. 그리고 이를 간선이 모두 제거될 때까지 반복한다.</li>
</ul>

<p><img src="/images/2021-02-25/037/unt.png" alt="unt.png" /></p>
<ul>
  <li>간선의 제거 정도에 따라서 다른 입도(Granularity)의 군집 구도가 나타난다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%205.png" alt="Untitled%205.png" /></p>
<ul>
  <li>이 때 간선을 얼마나 제거할 것인가는 군집성을 기준으로 삼는다. 즉 군집성이 최대가 되는 지점까지 간선을 제거한다.</li>
  <li>단 현재의 연결 요소들을 군집으로 가정하되, 최초의 입력 그래프에서 군집성을 계산한다.</li>
  <li>정리하면 Givan-Newman 알고리즘은 다음과 같다.
    <ol>
      <li>전체 그래프에서 시작한다.</li>
      <li>매개 중심성이 높은 순서로 간선을 제거하면서, 군집성을 기록한다.</li>
      <li>군집성이 가장 커지는 상황을 복원한다.</li>
      <li>이 때 서로 연결된 정점들, 즉 연결 요소를 하나의 군집으로 간주한다.</li>
    </ol>
  </li>
</ul>

<h2 id="louvain-알고리즘">Louvain 알고리즘</h2>

<ul>
  <li>Bottom-Up 방식의 알고리즘이다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%206.png" alt="Untitled%206.png" /></p>
<ul>
  <li>이 때에도 군집성이 기준으로 군집을 합친다.</li>
  <li>구체적인 알고리즘의 동작 과정은 다음과 같다.
    <ol>
      <li>개별 정점으로 구성된 크기 1의 군집들로부터 시작한다.</li>
      <li>각 정점 u를 기존 혹은 새로운 군집으로 이동한다. 이 때 군집성이 최대화되도록 군집을 결정한다.</li>
      <li>더 이상 군집성이 증가하지 않을 때까지 2)과정을 반복한다.</li>
    </ol>
  </li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%207.png" alt="Untitled%207.png" />
    4. 각 군집을 하나의 정점으로 하는 군집 레벨의 그래프를 얻은 뒤 다시 3)과정을 수행한다.</p>

<p><img src="/images/2021-02-25/037/Untitled%208.png" alt="Untitled%208.png" />
    5. 위의 과정을 반복하다가 군집성이 증가하지 않으면 알고리즘을 종료한다.</p>

<p><img src="/images/2021-02-25/037/Untitled%209.png" alt="Untitled%209.png" /></p>
<h1 id="중첩이-있는-군집-탐색">중첩이 있는 군집 탐색</h1>

<ul>
  <li>앞서 배운 Girvan-Newman 알고리즘, Louvain 알고리즘은 군집 간의 중첩이 없다고 가정한다.</li>
  <li>하지만 실제 그래프의 군집들은 중첩되어 있는 경우가 많다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2010.png" alt="Untitled%2010.png" /></p>
<ul>
  <li>중첩이 있는 군집을 구하기 위해 아래와 같은 중첩 군집 모형을 가정한다.
    <ol>
      <li>각 정점은 여러 개의 군집에 속할 수 있다.</li>
      <li>각 군집 A에 대해, 같은 군집에 속하는 두 정점은 $P_A$확률로 간선으로 직접 연결된다.</li>
      <li>두 정점이 여러 군집에동시에 속할 경우 간선 연결 확률은 독립적이다. 예를 들어 두 정점이 군집 A와 B에 동시에 속할 경우, 두 정점이 간선으로 직접 연결될 확률은 $1 - (1 - P_A)(1 - P_B)$이다.</li>
      <li>어느 군집에도 함께 속하지 않는 두 정점은 낮은 확률 $\epsilon$으로 직접 연결된다.</li>
    </ol>
  </li>
  <li>중첩 군집 모형이 주어지면, 주어진 그래프의 확률을 계산할 수 있다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2011.png" alt="Untitled%2011.png" /></p>
<ul>
  <li>중첩 군집 탐색은 주어진 그래프의 확률을 최대화하는 중첩 군집 모형을 찾는 과정이다. 통계 용어를 빌리면, 최우도 추정치(Maximum Likelihood Estimate)를 찾는 과정이다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2012.png" alt="Untitled%2012.png" /></p>
<ul>
  <li>중첩 군집 탐색을 용이하게 하기 위하여 <strong>완화된 중첩 군집 모형</strong>을 사용한다. 완화된 중첩 군집 모형에는 각 정점이 각 군집에 속해 있는 정도를 실숫값으로 표현한다.</li>
  <li>최적화 관점에서는 모형의 매개변수들이 실수 값을 가지기 때문에 익숙한 최적화 도구 (경사하강법 등)을 사용하여 모형을 탐색할 수 있다는 장점이 있다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2013.png" alt="Untitled%2013.png" /></p>
<h1 id="추천-시스템">추천 시스템</h1>

<ul>
  <li>추천 시스템은 사용자 각각이 구매할 만한 선호할 만한 상품/영화/영상을 추천한다.</li>
  <li>추천 시스템의 핵심은 사용자별 구매를 예측하거나 선호를 추정하는 것이다.</li>
  <li>그래프 관점에서 추천 시스템은 <strong>미래의 간선을 예측하는 문제</strong> 혹은 <strong>누락된 간선의 가중치를 추정하는 문제</strong>로 해석할 수 있다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2014.png" alt="Untitled%2014.png" /></p>
<h2 id="내용-기반content-based-추천시스템">내용 기반(Content-based) 추천시스템</h2>

<ul>
  <li>내용 기반(Content-based)추천은 <strong>각 사용자가 구매/만족했던 상품과 유사한 것</strong>을 추천하는 방법이다.</li>
  <li>예시로는 동일한 장르의 영화를 추천, 동일한 감독 혹은 배우가 출현한 영화를 추천, 동일한 카테고리의 상품을 추천 등이 있다.</li>
  <li>네용 기반 추천은 다음 네 가지 단계로 이루어진다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2015.png" alt="Untitled%2015.png" /></p>
<ol>
  <li>첫 단계는 선호했던 상품들의 상품 프로필(Item Profile)을 수집하는 단계이다.
    <ul>
      <li>어떤 상품의 상품 프로필이란 해당 상품의 특성을 나열한 벡터이다.</li>
    </ul>
  </li>
</ol>

<p><img src="/images/2021-02-25/037/Untitled%2016.png" alt="Untitled%2016.png" /></p>
<ol>
  <li>다음은 사용자 프로필(User Profile)을 구성하는 단계이다.
    <ul>
      <li>사용자 프로필은 선호한 상품의 상품 프로필을 선호도를 사용하여 가중 평균하여 계산한다. 즉 사용자 프로필 역시 벡터이다.</li>
      <li>앞선 영화 프로필 예시에서는 다음과 같은 형태의 사용자 프로필을 얻을 수 있다.</li>
    </ul>
  </li>
</ol>

<p><img src="/images/2021-02-25/037/Untitled%2017.png" alt="Untitled%2017.png" /></p>
<ol>
  <li>다음 단계는 사용자 프로필과 다른 상품들의 상품 프로필을 매칭하는 단계이다.
    <ul>
      <li>사용자 프로필 벡터 $\vec{u}$ 와 상품 프로필 벡터 $\vec v$의 코사인 유사도 $\dfrac {\vec u \cdot \vec v}{|\vec u| |\vec v|}$를 계산한다. 즉 두 벡터의 사이각의 코사인 값을 계산한다.</li>
      <li>코사인 유사도가 높을 수록 해당 사용자가 과거 선호했던 상품들과 해당 상품이 유사함을 의미한다.</li>
    </ul>
  </li>
  <li>마지막 단계는 사용자에게 상품을 추천하는 단계이다. 계산한 코사인 유사도가 높은 상품들을 추천한다.</li>
</ol>

<h3 id="장단점">장단점</h3>

<ul>
  <li>장점
    <ol>
      <li>다른 사용자의 구매 기록이 필요하지 않다.</li>
      <li>독특한 취향의 사용자에게도 추천 가능</li>
      <li>새 상품에 대해서도 추천 가능</li>
      <li>추천의 이유를 제공할 수 있다.</li>
    </ol>
  </li>
  <li>단점
    <ol>
      <li>상품에 대한 부가 정보가 없는 경우에는 사용할 수 없다.</li>
      <li>구매 기록이 없는 사용자에게는 사용할 수 없다.</li>
      <li>Overfitting으로 지나치게 협소한 추천을 할 위험이 있다.</li>
    </ol>
  </li>
</ul>

<h2 id="협업-필터링-추천시스템">협업 필터링 추천시스템</h2>

<ul>
  <li>사용자 - 사용자 협업 필터링은 다음 세 단계로 이루어진다.
    <ol>
      <li>추천의 대상 사용자를 x라고 하자. 우선 x와 <strong>유사한 취향의 사용자</strong>들을 찾는다.</li>
      <li>다음 단계로 유사한 취향의 사용자들이 <strong>선호한 상품</strong>을 찾는다.</li>
      <li>마지막으로 이 상품들을 x에게 추천한다.</li>
    </ol>
  </li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2018.png" alt="Untitled%2018.png" /></p>
<ul>
  <li>사용자 - 사용자 협업 필터링의 핵심은 유사한 취향의 사용자를 찾는 것이다.</li>
  <li>이 때 취향의 유사도를 계산해야 하는데 이는 <strong>상관 계수(Correlation Coefficient)</strong>를 통해 측정합니다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2019.png" alt="Untitled%2019.png" /></p>
<ul>
  <li>구체적으로 취향의 유사도를 가중치로 사용한 평점의 가중 평균을 통해 평점을 추정한다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2020.png" alt="Untitled%2020.png" /></p>
<ul>
  <li>앞서 설명한 방법을 통해, x가 아직 구매하지 않은 상품 각각에 대해 평점을 추정한다. 그리고 추정한 평점이 가장 높은 상품들을 x에게 추천한다.</li>
</ul>

<h3 id="장단점-1">장단점</h3>

<ul>
  <li>장점
    <ul>
      <li>상품에 대한 부가 정보가 없는 경우에도 사용할 수 있다.</li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li>충분한 수의 평점 데이터가 누적되어야 효과적이다.</li>
      <li>새 상품, 새로운 사용자에 대한 추천이 불가능하다.</li>
      <li>독특한 취향의 사용자에게 추천이 어렵다.</li>
    </ul>
  </li>
</ul>

<h2 id="추천-시스템의-평가">추천 시스템의 평가</h2>

<ul>
  <li>추천 시스템의 평가의 방법은 다음과 같다.
    <ol>
      <li>데이터를 훈련 데이터와 평가 데이터로 분리한다.</li>
      <li>평가 데이터를 비워 놓고 훈련 데이터를 이용해 평가 데이터를 추정한다.</li>
      <li><strong>추정한 평점과 실제 평가 데이터를 비교</strong>하여 오차를 측정한다.</li>
    </ol>
  </li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2021.png" alt="Untitled%2021.png" /></p>
<h3 id="평가-지표">평가 지표</h3>

<ul>
  <li>오차를 측정하는 지표로는 <strong>평균 제곱 오차(Mean Squared Error, MSE)</strong>가 많이 사용된다. 평가 데이터 내의 평점들의 집합을 T라고 한다. MSE는 아래 수식으로 계산한다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2022.png" alt="Untitled%2022.png" /></p>
<ul>
  <li><strong>평균 제곱근 오차(Root Mean Squared Error, RMSE)</strong>도 많이 사용된다.</li>
</ul>

<p><img src="/images/2021-02-25/037/Untitled%2023.png" alt="Untitled%2023.png" /></p>
<ul>
  <li>이 밖에도 다양한 지표가 사용된다.
    <ul>
      <li>추정한 평점으로 순위를 매긴 후, 실제 평점으로 매긴 순위와의 상관계수를 계산</li>
      <li>추천한 상품 중 실제 구매로 이루어진 것의 비율을 측정하기도 한다.</li>
      <li>추천의 순서 혹은 다양성까지 고려하는 지표들도 사용된다.</li>
    </ul>
  </li>
</ul>
:ET